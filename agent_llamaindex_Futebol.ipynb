{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a85bab-00b0-4666-8e68-b6080f74804d",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cdd242-a567-47da-a26b-e45f67c67e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# REFs:\n",
    "#https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/\n",
    "#https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_parallel_function_calling/\n",
    "#https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/agents/\n",
    "from llama_index.llms.oci_genai import OCIGenAI\n",
    "from llama_index.core.agent import ReActAgent #Framework to work with agents - they use a lot of intermediate prompts\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.llms import ChatMessage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2dcbf66-2844-406e-a158-26c2ba3fec60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compartment_id = os.environ[\"NB_SESSION_COMPARTMENT_OCID\"]\n",
    "command_r = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyawk6mgunzodenakhkuwxanvt6wo3jcpf72ln52dymk4wq\"\n",
    "command_r_plus = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceya7ozidbukxwtun4ocm4ngco2jukoaht5mygpgr6gq2lgq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9fe95e-5685-4439-b4e6-dbac3ad7909b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checa_rodada(inputs: int) -> str:\n",
    "    \"\"\"Checa os resultados a partir do número da rodada representada por um número inteiro\"\"\"\n",
    "  \n",
    "    df = pd.read_csv('Tabela_Futebol_Agents.csv')\n",
    "    \n",
    "    rodada = df[df['Rodada'] == int(inputs)]\n",
    "    \n",
    "    time_A = rodada['Time_A'].astype(str)\n",
    "    time_B = rodada['Time_B'].astype(str)\n",
    "    \n",
    "    gol_A = rodada['Gol_TimeA'].astype(str)\n",
    "    gol_B = rodada['Gol_TimeB'].astype(str)\n",
    "    \n",
    "    result = f\"{time_A.iloc[0]} {gol_A.iloc[0]} x {gol_B.iloc[0]} {time_B.iloc[0]}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def checa_times(inputs: str) -> str:\n",
    "    \"\"\"Checa os resultados a partir de 1 dos times que jogaram. Os nomes sempre começam com letra maiúscula.\n",
    "    Alguns exemplos de nomes de times: Vasco, São Paulo, Corinthians, Sport.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv('Tabela_Futebol_Agents.csv')\n",
    "    \n",
    "    time = inputs\n",
    "    \n",
    "    lista_time_A = df['Time_A'].unique()\n",
    "    lista_time_B = df['Time_B'].unique()\n",
    "\n",
    "    if time in lista_time_A:\n",
    "        time_A = time\n",
    "        time_B = df.loc[df['Time_A'] == time, 'Time_B'].iloc[0]\n",
    "        gol_A = df.loc[df['Time_A'] == time, 'Gol_TimeA'].iloc[0]\n",
    "        gol_B = df.loc[df['Time_A'] == time, 'Gol_TimeB'].iloc[0]\n",
    "\n",
    "        result = f\"{time_A} {gol_A} x {gol_B} {time_B}\"\n",
    "\n",
    "    elif time in lista_time_B:\n",
    "        time_B = time\n",
    "        time_A = df.loc[df['Time_B'] == time, 'Time_A'].iloc[0]\n",
    "        gol_A = df.loc[df['Time_B'] == time, 'Gol_TimeA'].iloc[0]\n",
    "        gol_B = df.loc[df['Time_B'] == time, 'Gol_TimeB'].iloc[0]\n",
    "\n",
    "        result = f\"{time_A} {gol_A} x {gol_B} {time_B}\"\n",
    "\n",
    "    return result\n",
    "\n",
    "# Define the tools\n",
    "tools = [checa_rodada, checa_times]\n",
    "\n",
    "functions = []\n",
    "for tool in tools:\n",
    "    functions.append(FunctionTool.from_defaults(tool)) #  FunctionTool é um contêiner usado para integrar essas funções como ferramentas para o agente\n",
    "\n",
    "# Initialize LLM with OCI Generative AI\n",
    "llm = OCIGenAI(\n",
    "    model=command_r_plus,#\"command_r_plus\", #https://docs.oracle.com/en-us/iaas/Content/generative-ai/chat-models.htm\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=compartment_id,\n",
    "    provider=\"cohere\",\n",
    "    context_size=\"128000\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=2500\n",
    ")\n",
    "\n",
    "# Initialize ReAct agent with the add tool\n",
    "agent = ReActAgent.from_tools(functions, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70838e77-afd6-40c1-9b32-fe4cb7d12146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ReActAgent.from_tools of <class 'llama_index.core.agent.react.base.ReActAgent'>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReActAgent.from_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1bb058-e10f-4d70-b19f-be710193e4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Portuguese. I need to use a tool to help me answer the question.\n",
      "Action: checa_times\n",
      "Action Input: {'inputs': 'Vasco'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Vasco 0 x 2 Flamengo\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: O Vasco perdeu de 0 a 2 para o Flamengo.\n",
      "\u001b[0mO Vasco perdeu de 0 a 2 para o Flamengo.\n"
     ]
    }
   ],
   "source": [
    "# Use the agent to perform an addition operation\n",
    "prompt =  \"\"\"\n",
    "Qual foi o resultado do jogo do Vasco?\n",
    "\"\"\"\n",
    "\n",
    "result = agent.chat(prompt) #chat(str(messages))\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0bdedd0-8b34-451c-958c-7558cf9af412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O resultado da segunda rodada foi Vasco 0 x 2 Flamengo.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccac60-3329-4066-b34b-d014b89fc65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch21_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch21_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
